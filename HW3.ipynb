{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1**\n",
    "Скачайте текст \"Литературных анекдотов\". Напишите функцию, которая будет читать файл, лемматизировать текст с помощью pymystem3 и записывать результат в новый файл. У функции должно бы два аргумента: путь к исходному файлу и путь к файлу с лемматизированным текстом. Вызов функции тоже должен быть прописан в решении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/mac/Desktop/Новая/python-dh-hw/literaryanecdotes.txt\", 'r', encoding='utf-8') as a:\n",
    "    jokes = a.read ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#чистим \n",
    "wordsjokes = []\n",
    "for word in jokes.split():\n",
    "    word = word.strip(\"!\\\"#$%&'()*+,./|}~„“«»†*—/\\-—-:;<=>?@[\\]^_`{\")\n",
    "    if len(word) != 0:\n",
    "        wordsjokes.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лемматизируем\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "lemmas = m.lemmatize(\" \".join(wordsjokes))\n",
    "\n",
    "lemjokes = ''.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('lemtext.txt', 'w')\n",
    "for lemtext in lemjokes:\n",
    "    f.write(lemtext)\n",
    "\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#записываем в новый файл\n",
    "with open(\"/Users/mac/Desktop/Snake/DH-Homework/lemtext.txt\", 'r', encoding='utf-8') as b:\n",
    "    lemtext = b.read ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#моя_функция\n",
    "def my_function(text, lemtxt):\n",
    "    with open (text, \"r\", encoding = \"utf-8\") as f:\n",
    "        tex = f.read()\n",
    "    m = Mystem()\n",
    "    lemmas = m.lemmatize(tex)\n",
    "    lemteext = ''.join(lemmas)\n",
    "\n",
    "    with open (lemtxt, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(lemteext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный файл literaryanecdotes.txt\n",
      "Конечный файл ancdtsfunny.txt\n"
     ]
    }
   ],
   "source": [
    "my_function (input (\"Исходный файл \"), input(\"Конечный файл \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2**    \n",
    "Очистите лемматизированный текст от стоп слов и посчитайте ipm для оставшихся. Выведите 20 самых частотных по этому параметру слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/mac/Desktop/Новая/python-dh-hw/rus_stopwords.txt\", \"r\", encoding= \"utf-8\") as a:\n",
    "    stoop = a.read ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#убираем стоп-слова\n",
    "stoplaugh = []\n",
    "for word in lemjokes.split():\n",
    "    if word not in stoop.split():\n",
    "        stoplaugh.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#считаем частотность\n",
    "from collections import Counter\n",
    "freqanecdot  = Counter (stoplaugh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2763\n"
     ]
    }
   ],
   "source": [
    "#смотрим сколько слов в лемматизированном тексте\n",
    "a = len(lemjokes.split())\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipm для всех коме стоп-слов\n",
    "frequency = {}\n",
    "for k, v in  freqanecdot.items():\n",
    "     frequency [k] = freqanecdot[k]/len(lemjokes.split())* 1000000\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('пушкин', 59), ('толстой', 33), ('гоголь', 31), ('однажды', 29), ('лев', 25), ('любить', 20), ('достоевский', 20), ('тургенев', 16), ('ребенок', 15), ('царствие', 15), ('небесный', 15), ('окно', 12), ('тверской', 12), ('бульвар', 12), ('приходить', 12), ('лермонтов', 12), ('федор', 11), ('михайлович', 11), ('идти', 10), ('герцен', 10)]\n"
     ]
    }
   ],
   "source": [
    "#20 самых частотных\n",
    "frequentlaught  = Counter (freqanecdot)\n",
    "print (frequentlaught.most_common(20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('пушкин', 21353.60115816142), ('толстой', 11943.539630836049), ('гоголь', 11219.688744118712), ('однажды', 10495.837857401375), ('лев', 9048.136083966703), ('любить', 7238.508867173362), ('достоевский', 7238.508867173362), ('тургенев', 5790.80709373869), ('ребенок', 5428.881650380022), ('царствие', 5428.881650380022), ('небесный', 5428.881650380022), ('окно', 4343.105320304017), ('тверской', 4343.105320304017), ('бульвар', 4343.105320304017), ('приходить', 4343.105320304017), ('лермонтов', 4343.105320304017), ('федор', 3981.1798769453494), ('михайлович', 3981.1798769453494), ('идти', 3619.254433586681), ('герцен', 3619.254433586681)]\n"
     ]
    }
   ],
   "source": [
    "#20 самых частотных по ipm\n",
    "sortbyipm = sorted(frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "print (sortbyipm[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**\n",
    "\n",
    "Сделайте полный морфологический разбор исходного текста. Напишите регулярное выражение, которое будет извлекать из тега только часть речи. Пройдитесь циклом по списку с разборами, который выдал pymystem3, извлекая из каждого разбора форму слова и его часть речи и записывая их в новый словарь (форма -- ключ, часть речи -- значение). Посчитайте абсолютную частоту для всех частей речи, а затем относительнную частоту (абсолютная частота / длина текста в словах)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "with open(\"/Users/mac/Desktop/Новая/python-dh-hw/literaryanecdotes.txt\", \"r\", encoding= \"utf-8\") as a:\n",
    "    anecdotlit = a.read ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "litanalyz = m.analyze(anecdotlit)\n",
    "allwordsanalize = {}\n",
    "for word in litanalyz:\n",
    "    try:\n",
    "        form = word [\"text\"]\n",
    "        gr = word['analysis'][0]['gr']\n",
    "        allwordsanalize[form] = gr\n",
    "    except (KeyError, IndexError) as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = re.compile(\"[A-Z]+\")\n",
    "\n",
    "allwords_pos = {}\n",
    "\n",
    "for k,v in allwordsanalize.items():\n",
    "    allwords_pos [k] = pos.match(v). group (0)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2840\n"
     ]
    }
   ],
   "source": [
    "a = len(anecdotlit.split())\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Считаем абсолютную частоту частей речи.\n",
    "# Чтобы всё получилось надо создать новый словарь, где ключом будет название части речи, а значением — его абсолютная частотность\n",
    "pos_frequency = {}\n",
    "for k, v in allwords_pos.items():\n",
    "    pos_frequency [v] = sum(value == v for value in allwords_pos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PR': 37, 'S': 440, 'V': 436, 'A': 100, 'ADV': 87, 'SPRO': 54, 'CONJ': 20, 'PART': 28, 'ADVPRO': 24, 'APRO': 51, 'ANUM': 2, 'INTJ': 7, 'NUM': 9}\n"
     ]
    }
   ],
   "source": [
    "print (pos_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013028169014084507\n",
      "0.15492957746478872\n",
      "0.15352112676056337\n",
      "0.035211267605633804\n",
      "0.03063380281690141\n",
      "0.019014084507042252\n",
      "0.007042253521126761\n",
      "0.009859154929577466\n",
      "0.008450704225352112\n",
      "0.01795774647887324\n",
      "0.0007042253521126761\n",
      "0.0024647887323943664\n",
      "0.0031690140845070424\n"
     ]
    }
   ],
   "source": [
    "#Очень хитрый ход написать функцию которая всё поделит, но я так проверяю правильность данных,которые потом получу\n",
    "def keyword_function(a, b):\n",
    "    return a/b\n",
    " \n",
    "print( keyword_function(b=2840, a = 37))\n",
    "print( keyword_function(b=2840, a = 440))\n",
    "print( keyword_function(b=2840, a = 436))\n",
    "print( keyword_function(b=2840, a = 100))\n",
    "print( keyword_function(b=2840, a = 87))\n",
    "print( keyword_function(b=2840, a = 54))\n",
    "print( keyword_function(b=2840, a = 20))\n",
    "print( keyword_function(b=2840, a = 28))\n",
    "print( keyword_function(b=2840, a = 24))\n",
    "print( keyword_function(b=2840, a = 51))\n",
    "print( keyword_function(b=2840, a = 2))\n",
    "print( keyword_function(b=2840, a = 7))\n",
    "print( keyword_function(b=2840, a = 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Считаем относительную частоту для всех частей речи и проверяем сходится ли с тем, что я насчитала ранее\n",
    "otnos_frequency = {}\n",
    "for k, v in  pos_frequency.items():\n",
    "    otnos_frequency [k] = pos_frequency[k]/len(anecdotlit.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PR': 0.013028169014084507, 'S': 0.15492957746478872, 'V': 0.15352112676056337, 'A': 0.035211267605633804, 'ADV': 0.03063380281690141, 'SPRO': 0.019014084507042252, 'CONJ': 0.007042253521126761, 'PART': 0.009859154929577466, 'ADVPRO': 0.008450704225352112, 'APRO': 0.01795774647887324, 'ANUM': 0.0007042253521126761, 'INTJ': 0.0024647887323943664, 'NUM': 0.0031690140845070424}\n"
     ]
    }
   ],
   "source": [
    "#Ура-ура всё получилось!\n",
    "print (otnos_frequency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
